#!/usr/bin/python3
# Figuring out the most common subsets is a hard problem.
# This takes a random sample of a set if there would be too many subsets for a given length.
# Finding subset patterns saves tons of bytes for picodex!

import itertools
from itertools import combinations # to get subsets
from collections import Counter # To keep counts of subset repeats
import random          # random sample if list is to big
import sys             # stderr log and stdin
from concurrent.futures import ThreadPoolExecutor # For running in parallel.
import math # For how many subsets of len x in thing

def log(*args):
  print(*args)
  sys.stdout.flush()

# This will return all subsets of a list if possible.
def get_subsets_with_len(subset_len, source_len, l): # only returns up to 100 subsets, but randomly distributed
  subsets = [frozenset(subset) for subset in combinations(random.sample(l, min(len(l), source_len)), subset_len)]
  return random.sample(subsets, min(len(subsets), 200))

def get_subsets(executor, subset_len, l):
  subs = []
  source_len = len(l)-1
  for source_len in range(len(l), subset_len-1, -1):
    if math.comb(source_len,subset_len) <= 10000:
      subs = get_subsets_with_len(subset_len, source_len, l)
      break

  return subs

# returns a list of sets
def get_all_subsets(executor, l):
  subs = []
  for subset_len in range(4,len(l)):
    for sub in get_subsets(executor, subset_len, l):
      subs.append(sub)
  return subs

# give it list of ints. output list of pairs
def ranges(i):
  for a, b in itertools.groupby(enumerate(i), lambda pair: pair[1] - pair[0]):
    b = list(b)
    yield b[0][1], b[-1][1]

# input: list of ints. output bytes saved (taking ranges into account
def calc_saving(vals, count):
  real_byte_len = sum([min(b-a, 2)+1 for a, b in ranges(vals)])
  cur_len=real_byte_len*count
  new_len = min(3, len(vals))*count
  return max(0, cur_len-new_len)

# sub group looks like:
def get_top_savings(lists):
  with ThreadPoolExecutor(max_workers=16) as executor:
    all_subs = set()

    # For each list, get all or a random sample of all the subsets if there are too many.
    futures = []
    for i, l in enumerate(lists):
      future = executor.submit(get_all_subsets, executor, l)
      futures.append(future)

    # Store all subsets found in a single set.
    for i, future in enumerate(futures):
      for fz in future.result():
        all_subs.add(fz)

    lists_as_sets = {frozenset(x) for x in lists}
    savings_arr = []
    for fz in all_subs:
      count = 0
      for listset in lists_as_sets:
        if fz.issubset(listset):
          count += 1
      # savings is how many bytes would be saved by storing a range.
      if count > 1: # 1 count will never save anything significant
        vals = sorted([int(x) for x in fz])
        savings_arr.append({
          "len": len(fz),
          "count": count,
          "savings": calc_saving(vals, count),
          "vals": vals,
          "valsSet": fz,
        })

    savings_set = set()
    final_arr = []
    for x in reversed(sorted(savings_arr, key=lambda x: x['savings'])):
      if len(savings_set & x["valsSet"]) == 0 and x["savings"] > 0:
        savings_set.update(x["valsSet"])
        final_arr.append(x)
    # try a saving. check if it saved space. if not, revert. then try next saving.
    # when done, print the new constant list, colon separated.
    return final_arr

if __name__ == "__main__":
  # Pass in lines with numbers separated by spaces.
  lines = [line.split(" ") for line in sys.stdin.read().split("\n")]
  lines = [[y for y in line if y != ""] for line in lines]
  lines = [line for line in lines if len(line) > 0]

  log("Calculating savings... (This is pretty slow. Up to around a minute or two on my machine.)")
  savings = get_top_savings(lines)
  total_savings = 0
  for stat in savings:
    log(f'SAV:{stat["savings"]}', f'CNT:{stat["count"]}', f'LEN:{stat["len"]}', '|', ' '.join([str(n) for n in stat["vals"]]))
    total_savings += stat["savings"]
  log("TOTAL SAVINGS:", total_savings)
